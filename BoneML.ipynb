{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYkg9Dz2IFg1"
      },
      "source": [
        "# Nombre  - Celular - Correo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_p3zZo5HqBk"
      },
      "source": [
        "\n",
        "### Descripción de los datos\n",
        "\n",
        "Los datos utilizados en este proyecto provienen de diversas fuentes y están compuestos por múltiples características que describen cada instancia. Se trata de un conjunto de datos que contiene información relevante para la clasificación, permitiendo aplicar técnicas de aprendizaje automático para obtener patrones útiles.\n",
        "\n",
        "### Estructura del conjunto de datos\n",
        "- **Cantidad de instancias:** [número de instancias]\n",
        "- **Características:** [lista de características]\n",
        "- **Clase objetivo:** [nombre de la clase objetivo]\n",
        "\n",
        "### Descripción de las características\n",
        "1. **Característica 1:** [Descripción]\n",
        "2. **Característica 2:** [Descripción]\n",
        "3. **Característica n:** [Descripción]\n",
        "\n",
        "Este conjunto de datos ha sido cuidadosamente preprocesado para asegurar su calidad y relevancia en las tareas de clasificación que se desarrollarán a continuación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnBW9YBaMc2U"
      },
      "source": [
        "##  1. Cargar librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yc06c5L9Mp7G"
      },
      "outputs": [],
      "source": [
        "# ejemplos\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4b4uorFMrec"
      },
      "source": [
        "## 2. Cargar conjunto de datos\n",
        "\n",
        "Se puede cargar desde cualquier fuente estructurada, como CSV, SQL, XML, entre otras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "gQeqjIEqM65C",
        "outputId": "87312dbd-0ef7-49cf-9bd3-3d4721e3d2de"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('nombre_de_su_archivo.csv', sep=\",\")\n",
        "df # es como se ve el dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Rbs_s_SF_i"
      },
      "source": [
        "# 3. Análisis y visualización del conjunto de datos\n",
        "\n",
        "- Estadísticas (df.info(), df.describe())\n",
        "- Histogramas (distribución normal)\n",
        "- Gráficos de dispersión para identificar correlaciones\n",
        "- Mapas de calor de la matriz de correlación\n",
        "- Boxplots para detectar outliers\n",
        "- Análisis de valores faltantes\n",
        "- Resumen de categorías (value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rMWTdJRV9Ir"
      },
      "source": [
        "## 4. Limpieza y Preparación del Conjunto de Datos\n",
        "\n",
        "### 4.1 Identificación de Valores Perdidos, Nulos y Anomalías\n",
        "- Realizar un análisis exploratorio de datos para detectar la presencia de valores faltantes y nulos.\n",
        "- Utilizar visualizaciones y estadísticas descriptivas para identificar anomalías y outliers en el conjunto de datos.\n",
        "\n",
        "### 4.2 Proceso de Limpieza de Datos\n",
        "- Eliminar o imputar los valores perdidos según su contexto y naturaleza.\n",
        "- Corregir inconsistencias en los formatos de los datos, como fechas y tipos numéricos.\n",
        "- Eliminar duplicados y registros irrelevantes que puedan afectar el análisis.\n",
        "\n",
        "### 4.3 Normalización y Transformación de Datos\n",
        "- Aplicar técnicas de normalización para asegurar que todas las variables estén en la misma escala.\n",
        "- Considerar el uso de transformaciones logarítmicas o de potencias para variables sesgadas.\n",
        "- Realizar la creación de nuevas características que puedan aportar valor al análisis.\n",
        "\n",
        "### 4.4 Validación de la Limpieza\n",
        "- Realizar un segundo análisis exploratorio para verificar la efectividad de la limpieza.\n",
        "- Asegurar que los datos estén listos para el modelado, atendiendo a la calidad y coherencia.\n",
        "\n",
        "### 4.5 Documentación del Proceso\n",
        "- Mantener un registro detallado de todas las acciones realizadas durante la limpieza de datos.\n",
        "- Documentar decisiones y métodos utilizados para futuras referencias y reproducibilidad del análisis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_m3tBTOcj4m"
      },
      "source": [
        "## 5. Modelo de machine learning \n",
        "\n",
        "### 5.1 Separar el DataFrame en variables independientes y la variable dependiente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSiH8VKFLvgI"
      },
      "outputs": [],
      "source": [
        "# Esta sección de código define las características y la variable objetivo para el modelo.\n",
        "caracteristicas = ['X1', 'X2', 'X3', 'X4']  # Lista de columnas de características utilizadas para las predicciones\n",
        "X = df[caracteristicas]  # Seleccionando las columnas de características del dataframe\n",
        "y = df['y_predict']  # Seleccionando la variable objetivo del dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv69-VoNcwjE"
      },
      "source": [
        "### 5.2 División del conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "Para realizar la partición de un conjunto de datos en subconjuntos de prueba y entrenamiento, se puede utilizar la función `train_test_split` de la biblioteca Scikit-learn. Esta función permite dividir los datos de manera aleatoria y controlar el tamaño de los subconjuntos.\n",
        "\n",
        "Para más información, consulte la documentación en el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijbDi5v0cC3j"
      },
      "outputs": [],
      "source": [
        "# Se importan las librerías necesarias\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Se separa el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # X es la matriz de características, y es la variable objetivo. Se asigna el 30% de los datos al conjunto de prueba y el 70% al conjunto de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KneBkJSudOBf"
      },
      "source": [
        "### 5.3 Implementación del Modelo de Aprendizaje Automático\n",
        "\n",
        "En esta sección, se presentará la implementación de un modelo de aprendizaje automático utilizando la biblioteca Scikit-learn. Para obtener más información y detalles sobre su uso, visite la documentación oficial en https://scikit-learn.org/stable/index.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0yztgb-dNzm",
        "outputId": "442683ff-2dc8-4676-91b2-9e6dbb506f8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Definir el modelo utilizando los parámetros especificados (ejemplo: modelo = LinearRegression())\n",
        "modelo = nombre_modelo(parametros)\n",
        "\n",
        "# Entrenar el modelo con los datos de entrada (X) y las etiquetas (y) (ejemplo: modelo.fit(X_train, y_train))\n",
        "modelo.fit(X, y)\n",
        "\n",
        "# Realizar predicciones usando el modelo entrenado en el conjunto de prueba (X_test) (ejemplo: y_pred = modelo.predict(X_test))\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Mostrar los valores predichos por el modelo (ejemplo: print(y_pred))\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO9qYuUJNHPH"
      },
      "source": [
        "#Implementar las metricas diagnosticas para evaluar el rendimiento del modelo de ML\n",
        "\n",
        "- Reporte de clasificacion https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILaJ8D-WvP_j"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltvs16RvcmJP",
        "outputId": "23b2989c-4117-4034-d316-57f42283b3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.86      0.44         7\n",
            "           1       0.99      0.84      0.91        86\n",
            "\n",
            "    accuracy                           0.84        93\n",
            "   macro avg       0.64      0.85      0.68        93\n",
            "weighted avg       0.93      0.84      0.87        93\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd9OuuQDPI1E"
      },
      "source": [
        "#Implementar las metricas diagnosticas de visualización\n",
        "\n",
        "- Matriz de confusión https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
        "- Curva ROC https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QpkmtpNLnx-4",
        "outputId": "37120b1d-4d26-47cf-daf8-d984a04aa24b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'roc_curve' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3062006788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot ROC curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "fpr1, tpr1, thresholds = roc_curve(y_test_encoded, y_pred_encoded)\n",
        "roc_auc = auc(fpr1, tpr1)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.1f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "\n",
        "plt.plot(fpr1, tpr1, color='black',\n",
        "         lw=lw, label='ROC curve (area = %0.1f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnN881nKtrF8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(cm)\n",
        "\n",
        "# Create a heatmap of the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(np.unique(y_test)))\n",
        "plt.xticks(tick_marks, np.unique(y_test))\n",
        "plt.yticks(tick_marks, np.unique(y_test))\n",
        "\n",
        "# Fill in the values of the confusion matrix\n",
        "for i in range(len(np.unique(y_test))):\n",
        "  for j in range(len(np.unique(y_test))):\n",
        "    plt.text(j, i, str(cm[i][j]), ha='center', va='center', color='white')\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8otMyjh1PrmZ"
      },
      "source": [
        "# Discusión de los resultados\n",
        "- Que tan bueno o malo fue el modelo para cada clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_zTXrnBP8qe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
